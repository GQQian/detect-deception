{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "seed=42\n",
    "embedding_dim = 100\n",
    "vocab_size = 12112\n",
    "lower = False\n",
    "FN0 = 'train_data'\n",
    "FN = 'vocabulary-embedding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "with open('data/polar_data.pkl', 'rb') as contentFile:\n",
    "    (positive_X, positive_Y, negative_X, negative_Y) = pickle.load(contentFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 800 800 800\n"
     ]
    }
   ],
   "source": [
    "print(len(positive_X), len(positive_Y), len(negative_X), len(negative_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain\n",
    "def get_vocab(lst):\n",
    "    vocabcount = Counter(w for txt in lst for w in txt)\n",
    "    vocab = list(map(lambda x: x[0], sorted(vocabcount.items(), key=lambda x: -x[1])))\n",
    "    return vocab, vocabcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vocab, vocabcount = get_vocab(positive_X+negative_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'the', ',', 'and', 'to', 'I', 'a', 'was', 'in', 'of', 'The', 'for', 'hotel', 'room', 'at', 'it', 'is', 'we', 'that', 'my', 'were', 'with', 'had', 'not', '!', 'on', 'Chicago', 'this', 'but', 'stay', 'very', 'our', 'have', 'We', \"n't\", 'you', 'they', 'be', 'there', 'would', 'from', 'as', 'are', 'all', 'me', 'staff', 'great', 'so', 'service', 'did']\n",
      "... 12110\n"
     ]
    }
   ],
   "source": [
    "print (vocab[:50])\n",
    "print ('...',len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". 13678\n",
      "the 12806\n",
      ", 8715\n",
      "and 7802\n",
      "to 6702\n",
      "I 6357\n",
      "a 6331\n",
      "was 5986\n",
      "in 3784\n",
      "of 3287\n",
      "The 3145\n",
      "for 2786\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for key in vocab:\n",
    "    print(key, vocabcount[key])\n",
    "    if(i > 10):\n",
    "        break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "empty = 0 # RNN mask of no data\n",
    "eos = 1  # end of sentence\n",
    "start_idx = eos+1 # first real word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_idx(vocab, vocabcount):\n",
    "    word2idx = dict((word, idx+start_idx) for idx,word in enumerate(vocab))\n",
    "    word2idx['<empty>'] = empty\n",
    "    word2idx['<eos>'] = eos\n",
    "    \n",
    "    idx2word = dict((idx,word) for word,idx in word2idx.items())\n",
    "\n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word2idx, idx2word = get_idx(vocab, vocabcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = '/data/glove.6b/glove.6B.%dd.txt'%embedding_dim\n",
    "fname = cwd + fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "glove_n_symbols = !wc -l {fname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_n_symbols = int(glove_n_symbols[0].split()[0])\n",
    "glove_n_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "glove_index_dict = {}\n",
    "glove_embedding_weights = np.empty((glove_n_symbols, embedding_dim))\n",
    "globale_scale=.1\n",
    "with open(fname, 'r') as fp:\n",
    "    i = 0\n",
    "    for l in fp:\n",
    "        l = l.strip().split()\n",
    "        w = l[0]\n",
    "        glove_index_dict[w] = i\n",
    "        glove_embedding_weights[i,:] = np.array(list(map(float,l[1:])))\n",
    "        i += 1\n",
    "glove_embedding_weights *= globale_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040815727600190289"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embedding_weights.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for w,i in glove_index_dict.items():\n",
    "    w = w.lower()\n",
    "    if w not in glove_index_dict:\n",
    "        glove_index_dict[w] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random-embedding/glove scale 0.0706949139514 std 0.0407991894667\n",
      "number of tokens, in small vocab, found in glove and copied to embedding 10752 0.8877146631439894\n"
     ]
    }
   ],
   "source": [
    "# generate random embedding with same scale as glove\n",
    "np.random.seed(seed)\n",
    "shape = (vocab_size, embedding_dim)\n",
    "scale = glove_embedding_weights.std()*np.sqrt(12)/2 # uniform and not normal\n",
    "embedding = np.random.uniform(low=-scale, high=scale, size=shape)\n",
    "print ('random-embedding/glove scale', scale, 'std', embedding.std())\n",
    "\n",
    "# copy from glove weights of words that appear in our short vocabulary (idx2word)\n",
    "c = 0\n",
    "for i in range(vocab_size):\n",
    "    w = idx2word[i]\n",
    "    g = glove_index_dict.get(w, glove_index_dict.get(w.lower()))\n",
    "    if g is None and w.startswith('#'): # glove has no hastags (I think...)\n",
    "        w = w[1:]\n",
    "        g = glove_index_dict.get(w, glove_index_dict.get(w.lower()))\n",
    "    if g is not None:\n",
    "        embedding[i,:] = glove_embedding_weights[g,:]\n",
    "        c+=1\n",
    "print ('number of tokens, in small vocab, found in glove and copied to embedding', c,c/float(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "embedding_size = embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12112, 100)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "glove_thr = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word2glove = {}\n",
    "for w in word2idx:\n",
    "    if w in glove_index_dict:\n",
    "        g = w\n",
    "    elif w.lower() in glove_index_dict:\n",
    "        g = w.lower()\n",
    "    elif w.startswith('#') and w[1:] in glove_index_dict:\n",
    "        g = w[1:]\n",
    "    elif w.startswith('#') and w[1:].lower() in glove_index_dict:\n",
    "        g = w[1:].lower()\n",
    "    else:\n",
    "        continue\n",
    "    word2glove[w] = g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of glove substitutes found 69\n"
     ]
    }
   ],
   "source": [
    "normed_embedding = embedding/np.array([np.sqrt(np.dot(gweight,gweight)) for gweight in embedding])[:,None]\n",
    "\n",
    "nb_unknown_words = 100\n",
    "\n",
    "glove_match = []\n",
    "for w,idx in word2idx.items():\n",
    "    if idx >= vocab_size-nb_unknown_words and w.isalpha() and w in word2glove:\n",
    "        gidx = glove_index_dict[word2glove[w]]\n",
    "        gweight = glove_embedding_weights[gidx,:].copy()\n",
    "        # find row in embedding that has the highest cos score with gweight\n",
    "        gweight /= np.sqrt(np.dot(gweight,gweight))\n",
    "        score = np.dot(normed_embedding[:vocab_size-nb_unknown_words], gweight)\n",
    "        while True:\n",
    "            embedding_idx = score.argmax()\n",
    "            s = score[embedding_idx]\n",
    "            if s < glove_thr:\n",
    "                break\n",
    "            if idx2word[embedding_idx] in word2glove :\n",
    "                glove_match.append((w, embedding_idx, s)) \n",
    "                break\n",
    "            score[embedding_idx] = -1\n",
    "glove_match.sort(key = lambda x: -x[2])\n",
    "print ('# of glove substitutes found', len(glove_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.606717960349 finagling => surliness\n",
      "0.597920408107 dimming => dim\n",
      "0.595313958508 odds => difference\n",
      "0.582304950447 ticky => tacky\n",
      "0.574744266935 Yup => ow\n",
      "0.574744266935 yup => ow\n",
      "0.571094304521 piddle => checkin\n",
      "0.567003136042 violently => rudely\n",
      "0.559965874663 kleenex => diapers\n",
      "0.559415451509 millionaire => banker\n"
     ]
    }
   ],
   "source": [
    "for orig, sub, score in glove_match[-20:-10]:\n",
    "    print (score, orig,'=>', idx2word[sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "glove_idx2idx = dict((word2idx[w],embedding_idx) for  w, embedding_idx, _ in glove_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_X = [[word2idx[token] for token in content] for content in positive_X]\n",
    "len(positive_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_X = [[word2idx[token] for token in content] for content in negative_X]\n",
    "len(negative_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "positive_X_train, positive_X_test, positive_Y_train, positive_Y_test = train_test_split(positive_X, positive_Y, \n",
    "                                                                      test_size=100, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 100, 700, 100)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_X_train), len(positive_X_test), len(positive_Y_train), len(positive_Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "negative_X_train, negative_X_test, negative_Y_train, negative_Y_test = train_test_split(negative_X, negative_Y, \n",
    "                                                                      test_size=100, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 100, 700, 100)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_X_train), len(negative_X_test), len(negative_Y_train), len(negative_Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76, 200, 5, 7, 57, 16, 3, 4381, 29, 152, 172, 7, 9, 27, 8, 126, 169, 2, 7, 9, 32, 441, 23, 99, 1455, 5, 21, 200, 32, 134, 53, 1052, 176, 134, 52, 270, 3, 2204, 482, 2, 861, 50, 9, 8, 286, 534, 30, 4, 686, 48, 14, 41, 31, 77, 2]\n"
     ]
    }
   ],
   "source": [
    "print(positive_X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "maxlen = 100\n",
    "\n",
    "positive_X_train = pad_sequences(positive_X_train, maxlen=100, value=0.)\n",
    "negative_X_train = pad_sequences(negative_X_train, maxlen=100, value=0.)\n",
    "\n",
    "positive_X_test = pad_sequences(positive_X_test, maxlen=100, value=0.)\n",
    "negative_X_test = pad_sequences(negative_X_test, maxlen=100, value=0.)\n",
    "\n",
    "positive_Y_train = to_categorical(positive_Y_train, nb_classes=2)\n",
    "negative_Y_train = to_categorical(negative_Y_train, nb_classes=2)\n",
    "\n",
    "positive_Y_test = to_categorical(positive_Y_test, nb_classes=2)\n",
    "negative_Y_test = to_categorical(negative_Y_test, nb_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net_positive = tflearn.input_data([None, 100])\n",
    "net_positive = tflearn.embedding(net_positive, input_dim=vocab_size, output_dim=128)\n",
    "net_positive = tflearn.lstm(net_positive, 128, dropout=0.8)\n",
    "net_positive = tflearn.fully_connected(net_positive, 2, activation='softmax')\n",
    "net_positive = tflearn.regression(net_positive, optimizer='adam', learning_rate=0.001,\n",
    "                         loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_positive = tflearn.DNN(net_positive, tensorboard_verbose=0, \n",
    "                             best_checkpoint_path = os.getcwd() + '/checkpoint/positive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"net_negative = tflearn.input_data([None, 100])\n",
    "net_negative = tflearn.embedding(net_negative, input_dim=vocab_size, output_dim=128)\n",
    "net_negative = tflearn.lstm(net_negative, 128, dropout=0.8)\n",
    "net_negative = tflearn.fully_connected(net_negative, 2, activation='softmax')\n",
    "net_negative = tflearn.regression(net_negative, optimizer='adam', learning_rate=0.001,\n",
    "                         loss='categorical_crossentropy')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"model_negative = tflearn.DNN(net_negative, tensorboard_verbose=0, \n",
    "                             best_checkpoint_path = os.getcwd() + '/checkpoint/negative/')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_positive.fit(positive_X_train, positive_Y_train, validation_set=(positive_X_test, positive_Y_test),\\n                   show_metric=True, n_epoch = 50)'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model_positive.fit(positive_X_train, positive_Y_train, validation_set=(positive_X_test, positive_Y_test),\n",
    "                   show_metric=True, n_epoch = 50)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 549  | total loss: \u001b[1m\u001b[32m0.01100\u001b[0m\u001b[0m | time: 1.842s\n",
      "| Adam | epoch: 050 | loss: 0.01100 - acc: 0.9994 -- iter: 640/700\n",
      "Training Step: 550  | total loss: \u001b[1m\u001b[32m0.01052\u001b[0m\u001b[0m | time: 3.031s\n",
      "| Adam | epoch: 050 | loss: 0.01052 - acc: 0.9995 | val_loss: 0.99697 - val_acc: 0.8000 -- iter: 700/700\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\"\"\"model_negative.fit(negative_X_train, negative_Y_train, validation_set=(negative_X_test, negative_Y_test),\n",
    "                   show_metric=True, n_epoch = 50)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/guanqiaoqian/Documents/machine_learning/fake_news/checkpoint/negative/8200\n"
     ]
    }
   ],
   "source": [
    "\"\"\"model_negative.load(os.getcwd() + '/checkpoint/negative/8200')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.81999999284744263]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model_negative.evaluate(negative_X_test,negative_Y_test)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/guanqiaoqian/Documents/machine_learning/fake_news/checkpoint/positive/8900\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Key Accuracy/Mean/moving_avg_1 not found in checkpoint\n\t [[Node: save_11/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_11/Const_0, save_11/RestoreV2_1/tensor_names, save_11/RestoreV2_1/shape_and_slices)]]\n\nCaused by op 'save_11/RestoreV2_1', defined at:\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-83-e2e6a27aa426>\", line 2, in <module>\n    best_checkpoint_path = os.getcwd() + '/checkpoint/positive/')\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tflearn/models/dnn.py\", line 65, in __init__\n    best_val_accuracy=best_val_accuracy)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tflearn/helpers/trainer.py\", line 147, in __init__\n    allow_empty=True)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1056, in __init__\n    self.build()\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 669, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Key Accuracy/Mean/moving_avg_1 not found in checkpoint\n\t [[Node: save_11/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_11/Const_0, save_11/RestoreV2_1/tensor_names, save_11/RestoreV2_1/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/guanqiaoqian/miniconda3/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key Accuracy/Mean/moving_avg_1 not found in checkpoint\n\t [[Node: save_11/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_11/Const_0, save_11/RestoreV2_1/tensor_names, save_11/RestoreV2_1/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-98748fddefc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_positive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/checkpoint/positive/8900'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tflearn/models/dnn.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, model_file, weights_only, **optargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m                      \u001b[0mcreated\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrestored\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \"\"\"\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         self.predictor = Evaluator([self.net],\n",
      "\u001b[0;32m/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tflearn/helpers/trainer.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, model_file, trainable_variable_only, variable_name_map, scope_for_restore, create_new_session, verbose)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0mrestorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrainable_variable_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestorer_trainvars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1457\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key Accuracy/Mean/moving_avg_1 not found in checkpoint\n\t [[Node: save_11/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_11/Const_0, save_11/RestoreV2_1/tensor_names, save_11/RestoreV2_1/shape_and_slices)]]\n\nCaused by op 'save_11/RestoreV2_1', defined at:\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/guanqiaoqian/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-83-e2e6a27aa426>\", line 2, in <module>\n    best_checkpoint_path = os.getcwd() + '/checkpoint/positive/')\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tflearn/models/dnn.py\", line 65, in __init__\n    best_val_accuracy=best_val_accuracy)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tflearn/helpers/trainer.py\", line 147, in __init__\n    allow_empty=True)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1056, in __init__\n    self.build()\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 669, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/guanqiaoqian/miniconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Key Accuracy/Mean/moving_avg_1 not found in checkpoint\n\t [[Node: save_11/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_11/Const_0, save_11/RestoreV2_1/tensor_names, save_11/RestoreV2_1/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "model_positive.load(os.getcwd() + '/checkpoint/positive/8900')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_positive.evaluate(positive_X_test,positive_Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
